{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden van de dataset\n",
    "dataset = pd.read_csv('./CasusData.csv')  # Vervang 'jouw_bestandsnaam.csv' door de werkelijke bestandsnaam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "### 1. Negeren van WAP's met een waarde van 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Negeren van WAP's met een waarde van 100\n",
    "dataset.replace(100, pd.NA, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Behandeling van ontbrekende waarden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Behandeling van ontbrekende waarden\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "dataset_imputed = pd.DataFrame(imputer.fit_transform(dataset), columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature scaling (normalisatie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature scaling (normalisatie)\n",
    "# Hier gebruiken we StandardScaler om de features te normaliseren.\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(dataset_imputed.iloc[:, :520])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. K-means clustering voor groepering van locaties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. K-means clustering voor groepering van locaties\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "dataset['LOCATION_CLUSTER'] = kmeans.fit_predict(features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Doelvariabele (WALKING_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Nieuwe kolom: WALKING_PATTERN (bijvoorbeeld op basis van locatieverandering)\n",
    "dataset['WALKING_PATTERN'] = (dataset['LATITUDE'].diff() != 0) | (dataset['LONGITUDE'].diff() != 0)\n",
    "dataset['WALKING_PATTERN'] = dataset['WALKING_PATTERN'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Groeperen op individuele gebruikers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Groeperen op individuele gebruikers\n",
    "grouped_data = dataset.groupby('USERID').agg({\n",
    "    'WALKING_PATTERN': 'max',  # Aggregeer het wandelpatroon (max waarde over tijd)\n",
    "    'LOCATION_CLUSTER': 'max',  # Aggregeer de locatiecluster (max waarde over tijd)\n",
    "    # Voeg andere gewenste aggregaties toe voor extra informatie\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doelvariabele\n",
    "target = grouped_data['WALKING_PATTERN']\n",
    "\n",
    "# Features voor voorspelling (bijvoorbeeld locatiecluster)\n",
    "features_grouped = grouped_data[['LOCATION_CLUSTER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split de data in trainings- en testsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_grouped, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train een Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorspel de WALKING_PATTERN op de testset\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# Evaluatie van het model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eenvoudige analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gedetailleerde evaluatie\n",
    "print('Classification Report:\\n', classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
